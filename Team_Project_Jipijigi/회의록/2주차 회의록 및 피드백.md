2주차 회의록
=============

< 11월 15일 오후 스크럼 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

#### 1. 현재 진행 중인 프로젝트의 구체적인 목적이 필요함.
* 하지만, 애초에 포괄적으로 시작했기 때문에 특정한 목적을 정하기가 애매함.
* 우선 데이터를 모아서 그래프로써 시각화하는 기능(최소 구현 기능)을 구현하고, 그 과정에서 추가로 적용할 수 있는 기능을 고민해보기로 결정.

#### 2. 추후 merge를 진행할 경우, 오류나 혼동이 없도록 코드 스타일을 최대한 통일해야할 것으로 보임.
* indent 스페이스(탭 키 한 번에 입력되는 기본 칸 수)는 4칸
* 함수명: 'do_ + 명사' 형태의 스네이크 표기법 ex) do_world
* 변수명: '명사 + 명사' 형태의 스네이크 표기법 ex) my_world
* 클래스명: 대문자로 시작하는 카멜 표기법 ex) MyWorld


***
< 11월 15일 오후 코치님(데이터 분석) 피드백 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

Q1. 키워드 분석을 통한 데이터 시각화 및 분석도 진행하고 싶은데, 어떤 키워드를 추려서 해야 좋을지?

A1. 우선은 분석을 전체적으로 진행해보고 만약 데이터가 너무 광범위하다고 생각이 든다면, 3분류에 있는 키워드를 추가로 더하거나, 2분류의 3분류를 통합해서 사용하는 방법도 있음.

* 문화(영화) 데이터의 경우 이슈를 통해 영화관 기업별 매출 변화와 관련된 데이터를 얻을 수 있는 방법이나 관련 기업들에 대한 자료를 제공해 줄 예정

* 구글 colab: 구글에서 제공하는 파이썬 실습환경(크롤링을 할 때 쓰면 좋음) ----> 크롤링이 안 될 경우 (런타임 > 런타임 초기화)로 반복해서 하는 방법이 있다.

* 이슈나 readme 작성 디테일하게 해주면 좋음.


***
< 11월 16일 오후 회의 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

#### 1. 프로젝트 진행 상황 중간 점검 및 방향성 수정
* 1주차까지는 모든 인원이 데이터 수집부터 시각화까지 전체적인 과정을 경험해보며, 개인의 역량을 높이는 데에 의미를 뒀음.
* 하지만 개개인의 몰입도와 프로젝트 진행 속도 등의 모든 측면에서 큰 발전이 없다고 판단.
* 서비스로써의 기능과 가치, 원활한 데이터 제공을 위해 DB를 사용하기로 결정.
* 각자 분담한 업무를 진행하며, 상황 판단 하에 추가 기능은 언제든 자유롭게 얘기할 것. ex) 페이지의 사용 예시, 튜토리얼을 모달 팝업창을 통해 정보 제공
* 각자의 업무와 분야는 아래와 같이 분담하기로 결정.
  * 프론트엔드(웹 구성 및 그래프를 클라이언트에 표출): 안성진, 용다운
  * 백엔드(DB 환경 구축 및 데이터 저장과 질의): 조윤기, 조재우
  * 데이터 분석(DB 데이터 분석 및 시각화를 통한 인사이트 도출): 최호진, 한명빈

#### 2. 웹의 UI와 그래프 양식 통일 필요성 언급. 웹은 전체적으로 메인 페이지, 각 테마별 페이지(각 테마의 페이지 양식은 통일), 반응형 페이지(모바일 화면 등) 예상

#### 3. 디스코드 방 구성: 채팅 채널 총 3개(공지사항, 자료공유, 프리토킹), 음성 채널 총 4개(전체, 프론트엔드, 백엔드, 데이터 분석)

#### 4. 분석은 각 테마의 데이터에 정부 정책 단계 혹은 신규 확진자 수와 같은 요소 사이의 경향을 파악해보는 것으로 고려 중.


***
< 11월 17일 오후 스크럼 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

#### 1. 각 담당 파트 상황 보고
* 프론트엔드
  * 현재 메인 페이지와 차트를 표현할 페이지의 UI 구성 계획 및 작성 중에 있음.
  * 현재 작성한 메인 페이지는 전체적인 요소와 글자 크기를 더 키우고, 추후에 적절한 백그라운드 이미지가 있으면 좋을 것 같다는 피드백을 받음.
  * 백엔드와 데이터를 주고 받는 부분에 있어서 맞춰갈 예정.
* 백엔드
  * DB에 데이터를 저장하고, 이를 SQL Alchemy를 통해 쿼리, flask를 통해 데이터 전달까지 기본적인 뼈대는 구현함.
  * 더 많은 데이터를 DB에 저장하고, 원활한 데이터 쿼리 및 전송이 가능하도록 노력 예정.
* 데이터 분석
  * 더 다양하고 많은 데이터 수집과 유의미한 인사이트 및 분석 고려 중에 있음.
  * 원활하고 디테일한 데이터 수집을 위한 방법도 모색 중에 있음.

#### 2. 고려 가능한 구체적인 UI 및 기능 관련 의견
* 일단 현재로써는 그래프를 시각화하는 페이지의 구성에 대해 구체적인 UI가 필요하다고 느낌. 일단 기존 코로나 관련 데이터 시각화 페이지 참고하여 작성 예정
* 그래프에 대한 범위 슬라이더(사용자가 더 유동적으로 기간을 선택할 수 있도록)도 있으면 좋겠음.
* 서비스 페이지를 어떤 식으로 사용할 수 있는지 알려주는 튜토리얼 방식의 모달 팝업창도 가능하다면 추가 예정.




***
< 11월 17일 오후 코치님(웹) 피드백 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

Q1. 웹에서 더 자연스럽게 창이 새로고침되는 것, 즉, 페이지에서 변화가 없는 부분은 그대로 있고, 나머지 부분만 변화(새로고침)되는 비동기 처리를 어떻게 구현할 수 있는지?

A1. 새로 학습하는 속도를 빠르게 습득할 수 있다면, 리액트나 뷰도 추천. 
질문 내용은 어떻게 보면 클라이언트 사이드에서 렌더링하는 것을 의미하는데, 굳이 여러 페이지를 라우팅할 필요 없고, 하나의 라우터이자 하나의 페이지(html+JS)에서 요소만을 변경하며 선택에 따라 보여지는 요소가 달라지도록 하는 방법도 추천. ⇒ html의 돔 요소 변경


Q2. 리액트나 뷰 중 어느 것을 주로 사용하시는지?

A2. 리액트가 대부분. 하지만 처한 상황에 따라 툴을 정하는 것이 제일 중요.
기본적으로 일반 JS에서 불필요한 반복 작업을 피하기 위해 리액트를 씀. ⇒ 리액트는 html의 돔 수정에 유용.


Q3. 백엔드가 구축한 DB 서버를 다른 팀원도 이용할 수 있게 하려면 어떻게 해야 하는지?

A3. 머지를 통해 모두가 코드와 환경을 공유하는 과정이 한 번 필요할 것 같음. 우선, 로컬의 DB는 아틀라스나 AWS를 통해 다른 팀원들도 이용할 수 있게 하는 것 추천. 또는 몽고 덤프, MySQL 덤프라는 명령 등을 통해 DB를 다운로드, 이동, 전송 등이 가능. 이 부분도 알아보고 처한 상황에 알맞은 방법을 정하면 좋을 것 같음.

* 추가로 머지 리퀘스트를 진행할 때, 리뷰어로 웹 코치님을 설정하면 웹 코치님도 확인 가능.


***
< 11월 19일 오전 스크럼 및 주간 정리 회의 >
-------------
#### 참여 인원: 안성진, 용다운, 조윤기, 조재우, 최호진, 한명빈

#### 1. 스크럼
- 백엔드: 현재 리스트 형태로 데이터 전송은 가능. jsonify로 보내는 방법은 더 알아봐야 할 듯. 또, DB 서버를 열어서 각자의 환경에서 DB 서버에 접속할 수 있도록 구축 중. 오전 10시 반 기준으로 70% 정도 완성.
- 프론트엔드: chart.js + React.js를 통해 동적인 그래프 시각화 가능(단, 일관된 형태의 jsonify 데이터를 받았을 때만). 현재는 페이지 사이에서 어떤 방식으로 이동할지(하나의 페이지에서 클릭을 통해 컴포넌트 변경, 여러 페이지 자체를 만들고 클릭을 통해 이동 등) 고민 중.

#### 2. 주간 정리 회의
- 프론트엔드
  - 메인 페이지와 차트 시각화 페이지 대략적으로 구성. 이를 다시 리액트 js로 재구성 중. 아직 페이지 사이의 이동은 구현 못한 상태.
  - 별도로 얻은 코로나 관련 전세계 데이터 API를 통해 그래프 시각화는 가능한 상태.
  - 백엔드에서 데이터를 json 형태로 보내주는 것이 제일 바람직하고 편하다고 판단(key값이 있는 데이터 형태)되기 때문에, 백엔드에서 이런 방향으로 일관된 json 형태 파일로 보내주면 좋겠다는 의견이 있음.
- 백엔드
  - 일단 로컬 DB를 공유하는 것으로 시도를 했지만, 현장의 IP가 다른 IP 접근을 막고 있는 상태이기 때문에 불가능하다고 판단. 각각 Azure와 AWS를 통해 DB 공유 환경 구축을 진행해봤고, 현재는 AWS를 통해 공유할 수 있는 상태까지 완료.
  - 현재 파이썬의 리스트 형태로 프론트엔드에 데이터 전달은 가능한 상태이고, 프론트엔드의 의견을 따라서 json 형태로 데이터를 보낼 수 있도록 수정해볼 예정.
  - 모든 데이터에 대한 DB를 완성하기 위해서 각자 수집했던 데이터를 보내주면 좋겠다는 의견이 있음.
- 데이터 분석
  - 신규확진자 수, 거리두기 단계 등에 따른 영화, 공연, 소비, 네이버 검색어, 지하철 승하차 데이터를 일반 회귀 분석과 다중 회귀 분석을 시도해본 상태. 현재까지는 다중 회귀 분석을 진행했을 때 비교적 눈에 띄는, 유의미한 수치 결과가 나옴.
  - 각 분석에서는 다중 회귀를 통해 summary를 뽑아내고, 이를 통해 임의로 각 요소의 경향과 상관 관계를 대략 파악해본 상태.
  - 프론트엔드쪽에서 3D, 입체 그래프 형태로 차트를 시각화해줄 수 있으면 좋겠다는 의견이 있음. 더 직관적 또는 더 좋은 방향으로 분석 결과, 인사이트를 제공할 수 있을 것으로 생각되기 때문.
  - 현재 페이지 레이아웃 외에 별도로 분석 관련 페이지도 있으면 좋을 것 같다는 생각도 들었음. 가벼운 분석, 흥미로운 분석 등을 보여줄 수 있을 것으로 생각되기 때문. 현재는 각 카테고리마다 별도로 더 자세한 분석 페이지를 볼 수 있도록 페이지 구성을 만들면 좋을 것 같다.


